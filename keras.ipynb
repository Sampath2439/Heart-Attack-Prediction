{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Heart Rate: 78.25 bpm (Normal)\n"
     ]
    }
   ],
   "source": [
    "# Function to check if the average heart rate is normal\n",
    "def is_normal_heart_rate(heart_rate):\n",
    "    normal_range = (60, 100)  # Normal heart rate range in bpm for adults\n",
    "    \n",
    "    if normal_range[0] <= heart_rate <= normal_range[1]:\n",
    "        return True  # Heart rate is normal\n",
    "    else:\n",
    "        return False  # Heart rate is abnormal\n",
    "\n",
    "# Function to calculate average heart rate from R-R intervals in milliseconds\n",
    "def calculate_average_heart_rate(rr_intervals_ms):\n",
    "    # Calculate average R-R interval in milliseconds\n",
    "    average_rr_interval_ms = sum(rr_intervals_ms) / len(rr_intervals_ms)\n",
    "    \n",
    "    # Calculate average heart rate in beats per minute (bpm)\n",
    "    average_heart_rate_bpm = round(60000 / average_rr_interval_ms, 2)\n",
    "    \n",
    "    return average_heart_rate_bpm\n",
    "\n",
    "# Sample input data representing 100 R-R intervals in milliseconds for a single person\n",
    "rr_intervals_ms = [64 ,252  ,355  ,470  ,580  ,739  ,852  ,960 ,1067 ,1174 ,1287 ,1401]\n",
    "\n",
    "average_heart_rate = calculate_average_heart_rate(rr_intervals_ms)\n",
    "\n",
    "\n",
    "if is_normal_heart_rate(average_heart_rate):\n",
    "    print(f\"Average Heart Rate: {average_heart_rate} bpm (Normal)\")\n",
    "else:\n",
    "    print(f\"Average Heart Rate: {average_heart_rate} bpm (Abnormal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rates = np.array([353.0, 323.0, 323.0, 330.0, 332.0, 330.0, 330.0, 328.0, 338.0, 343.0, 366.0, 343.0, 331.0, 365.0, 404.0, 314.0, 315.0, 323.0, 328.0, 356.0, 348.0, 318.0, 321.0, 323.0, 322.0, 324.0, 323.0, 318.0, 326.0, 347.0, 328.0, 330.0, 363.0, 408.0, 322.0, 323.0, 333.0, 342.0, 364.0, 351.0, 325.0, 327.0, 329.0, 330.0, 329.0, 331.0, 339.0, 344.0, 326.0, 325.0, 628.0, 326.0, 314.0, 325.0, 332.0, 350.0, 362.0, 327.0, 323.0, 322.0, 327.0, 325.0, 323.0, 324.0, 347.0, 326.0, 323.0, 315.0, 534.0, 317.0, 308.0, 321.0, 330.0, 347.0, 357.0, 320.0, 314.0, 316.0, 323.0, 323.0, 322.0, 327.0, 333.0, 345.0, 331.0, 314.0, 307.0, 489.0, 317.0, 310.0, 318.0, 324.0, 348.0, 357.0, 319.0, 315.0, 317.0, 319.0, 316.0, 321.0, 319.0, 322.0, 327.0, 324.0, 352.0, 340.0, 328.0, 566.0, 342.0, 303.0, 314.0, 326.0, 360.0, 395.0, 359.0, 317.0, 315.0, 303.0, 324.0, 333.0, 465.0, 593.0, 645.0, 653.0, 656.0, 618.0, 587.0, 648.0, 655.0, 480.0, 458.0, 449.0, 447.0, 447.0, 400.0, 357.0, 345.0, 338.0, 325.0, 315.0, 307.0, 302.0, 296.0, 306.0, 296.0, 278.0, 278.0, 542.0, 275.0, 274.0, 281.0, 275.0, 315.0, 321.0, 280.0, 283.0, 259.0, 300.0, 257.0, 278.0, 281.0, 285.0, 295.0, 300.0, 271.0, 274.0, 618.0, 277.0, 271.0, 279.0, 332.0, 661.0, 661.0, 660.0, 660.0, 660.0, 661.0, 661.0, 660.0, 658.0, 585.0, 521.0, 449.0, 378.0, 591.0, 281.0, 215.0, 194.0, 187.0, 173.0, 182.0, 136.0, 121.0, 145.0, 128.0, 128.0, 130.0, 150.0, 151.0, 147.0, 149.0, 310.0, 169.0, 182.0, 188.0, 197.0, 220.0, 230.0, 220.0, 216.0, 243.0, 240.0, 257.0, 267.0, 289.0, 280.0, 283.0])\n",
    "\n",
    "labels = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(heart_rates, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train.reshape(-1, 1))\n",
    "X_test_normalized = scaler.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(1,)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "])\n",
    "opt=Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"heart_rate_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 1s 34ms/step - loss: 0.6900 - accuracy: 0.5318 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6832 - accuracy: 0.5780 - val_loss: 0.6966 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6802 - accuracy: 0.5780 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6779 - accuracy: 0.5780 - val_loss: 0.7007 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.5780 - val_loss: 0.7023 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6748 - accuracy: 0.5780 - val_loss: 0.7038 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6742 - accuracy: 0.5780 - val_loss: 0.7055 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6731 - accuracy: 0.5780 - val_loss: 0.7053 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6727 - accuracy: 0.5780 - val_loss: 0.7060 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.5780 - val_loss: 0.7072 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6712 - accuracy: 0.5780 - val_loss: 0.7073 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.7073 - accuracy: 0.5000\n",
      "Test Loss: 0.7073229551315308\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_normalized, Y_train, epochs=200, batch_size=20, validation_data=(X_test_normalized, Y_test), callbacks=[early_stopping])\n",
    "loss, accuracy = model.evaluate(X_test_normalized, Y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6710 - accuracy: 0.5780 - val_loss: 0.7092 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6704 - accuracy: 0.5780 - val_loss: 0.7067 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6693 - accuracy: 0.5780 - val_loss: 0.7071 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6688 - accuracy: 0.5780 - val_loss: 0.7078 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6679 - accuracy: 0.5780 - val_loss: 0.7075 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6667 - accuracy: 0.5780 - val_loss: 0.7062 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6655 - accuracy: 0.5780 - val_loss: 0.7041 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6633 - accuracy: 0.5954 - val_loss: 0.7007 - val_accuracy: 0.5227\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6618 - accuracy: 0.6127 - val_loss: 0.6970 - val_accuracy: 0.5455\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6596 - accuracy: 0.6301 - val_loss: 0.6966 - val_accuracy: 0.5455\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6573 - accuracy: 0.6358 - val_loss: 0.6940 - val_accuracy: 0.5682\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6554 - accuracy: 0.6590 - val_loss: 0.6906 - val_accuracy: 0.5909\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6519 - accuracy: 0.6590 - val_loss: 0.6883 - val_accuracy: 0.5909\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6496 - accuracy: 0.6590 - val_loss: 0.6860 - val_accuracy: 0.5909\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6467 - accuracy: 0.6590 - val_loss: 0.6830 - val_accuracy: 0.6136\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6433 - accuracy: 0.6705 - val_loss: 0.6792 - val_accuracy: 0.6364\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6409 - accuracy: 0.6705 - val_loss: 0.6740 - val_accuracy: 0.6364\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6368 - accuracy: 0.6763 - val_loss: 0.6716 - val_accuracy: 0.6364\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.6763 - val_loss: 0.6681 - val_accuracy: 0.6364\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6297 - accuracy: 0.6821 - val_loss: 0.6641 - val_accuracy: 0.6364\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6260 - accuracy: 0.6879 - val_loss: 0.6600 - val_accuracy: 0.6364\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6223 - accuracy: 0.6879 - val_loss: 0.6572 - val_accuracy: 0.6364\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6176 - accuracy: 0.6936 - val_loss: 0.6499 - val_accuracy: 0.6364\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6133 - accuracy: 0.7052 - val_loss: 0.6447 - val_accuracy: 0.6364\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6095 - accuracy: 0.7052 - val_loss: 0.6397 - val_accuracy: 0.6364\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6035 - accuracy: 0.7110 - val_loss: 0.6343 - val_accuracy: 0.6364\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6006 - accuracy: 0.7052 - val_loss: 0.6283 - val_accuracy: 0.6364\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.7283 - val_loss: 0.6230 - val_accuracy: 0.6364\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5900 - accuracy: 0.7225 - val_loss: 0.6188 - val_accuracy: 0.6364\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5847 - accuracy: 0.7283 - val_loss: 0.6130 - val_accuracy: 0.6364\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5790 - accuracy: 0.7283 - val_loss: 0.6064 - val_accuracy: 0.6364\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5741 - accuracy: 0.7399 - val_loss: 0.5992 - val_accuracy: 0.6364\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5697 - accuracy: 0.7225 - val_loss: 0.5933 - val_accuracy: 0.6818\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5630 - accuracy: 0.7803 - val_loss: 0.5852 - val_accuracy: 0.7045\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5578 - accuracy: 0.7746 - val_loss: 0.5819 - val_accuracy: 0.6818\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5528 - accuracy: 0.7572 - val_loss: 0.5743 - val_accuracy: 0.7045\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5491 - accuracy: 0.7977 - val_loss: 0.5647 - val_accuracy: 0.7273\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7861 - val_loss: 0.5627 - val_accuracy: 0.6818\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7746 - val_loss: 0.5569 - val_accuracy: 0.7273\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7919 - val_loss: 0.5510 - val_accuracy: 0.7045\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7919 - val_loss: 0.5437 - val_accuracy: 0.7273\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5218 - accuracy: 0.7977 - val_loss: 0.5380 - val_accuracy: 0.7273\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.7977 - val_loss: 0.5345 - val_accuracy: 0.7273\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.7977 - val_loss: 0.5282 - val_accuracy: 0.7045\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.8092 - val_loss: 0.5201 - val_accuracy: 0.8182\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.8266 - val_loss: 0.5183 - val_accuracy: 0.7955\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5007 - accuracy: 0.8208 - val_loss: 0.5111 - val_accuracy: 0.8182\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4955 - accuracy: 0.8208 - val_loss: 0.5070 - val_accuracy: 0.7955\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4943 - accuracy: 0.7977 - val_loss: 0.5094 - val_accuracy: 0.8182\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4897 - accuracy: 0.8266 - val_loss: 0.4982 - val_accuracy: 0.8182\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.8208 - val_loss: 0.4974 - val_accuracy: 0.7955\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.8150 - val_loss: 0.4888 - val_accuracy: 0.8409\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.8150 - val_loss: 0.4880 - val_accuracy: 0.8182\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4749 - accuracy: 0.8150 - val_loss: 0.4848 - val_accuracy: 0.8182\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.8208 - val_loss: 0.4842 - val_accuracy: 0.8182\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.8266 - val_loss: 0.4828 - val_accuracy: 0.8409\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.8266 - val_loss: 0.4820 - val_accuracy: 0.8182\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.8150 - val_loss: 0.4764 - val_accuracy: 0.8409\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8208 - val_loss: 0.4716 - val_accuracy: 0.8409\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.8150 - val_loss: 0.4706 - val_accuracy: 0.8182\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4554 - accuracy: 0.8266 - val_loss: 0.4715 - val_accuracy: 0.8182\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.8208 - val_loss: 0.4677 - val_accuracy: 0.8182\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8208 - val_loss: 0.4621 - val_accuracy: 0.8409\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.8092 - val_loss: 0.4610 - val_accuracy: 0.8409\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.8266 - val_loss: 0.4559 - val_accuracy: 0.8636\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8150 - val_loss: 0.4552 - val_accuracy: 0.8409\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.8208 - val_loss: 0.4525 - val_accuracy: 0.8636\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.8266 - val_loss: 0.4527 - val_accuracy: 0.8636\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8150 - val_loss: 0.4514 - val_accuracy: 0.8409\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.8266 - val_loss: 0.4504 - val_accuracy: 0.8636\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.8208 - val_loss: 0.4517 - val_accuracy: 0.8182\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.8150 - val_loss: 0.4452 - val_accuracy: 0.8636\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.8208 - val_loss: 0.4463 - val_accuracy: 0.8636\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.8266 - val_loss: 0.4429 - val_accuracy: 0.8636\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4269 - accuracy: 0.8266 - val_loss: 0.4411 - val_accuracy: 0.8636\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.8208 - val_loss: 0.4413 - val_accuracy: 0.8409\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8266 - val_loss: 0.4348 - val_accuracy: 0.8636\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.8208 - val_loss: 0.4337 - val_accuracy: 0.8636\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8266 - val_loss: 0.4338 - val_accuracy: 0.8636\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8439 - val_loss: 0.4358 - val_accuracy: 0.8636\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8266 - val_loss: 0.4364 - val_accuracy: 0.8409\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8150 - val_loss: 0.4348 - val_accuracy: 0.8636\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.8324 - val_loss: 0.4296 - val_accuracy: 0.8636\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4142 - accuracy: 0.8266 - val_loss: 0.4305 - val_accuracy: 0.8636\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8266 - val_loss: 0.4303 - val_accuracy: 0.8636\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4128 - accuracy: 0.8266 - val_loss: 0.4290 - val_accuracy: 0.8636\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8382 - val_loss: 0.4245 - val_accuracy: 0.8636\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8208 - val_loss: 0.4222 - val_accuracy: 0.8636\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8324 - val_loss: 0.4208 - val_accuracy: 0.8636\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4072 - accuracy: 0.8266 - val_loss: 0.4233 - val_accuracy: 0.8636\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8266 - val_loss: 0.4206 - val_accuracy: 0.8636\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.8324 - val_loss: 0.4229 - val_accuracy: 0.8636\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8324 - val_loss: 0.4208 - val_accuracy: 0.8636\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8324 - val_loss: 0.4204 - val_accuracy: 0.8636\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8266 - val_loss: 0.4194 - val_accuracy: 0.8636\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.8324 - val_loss: 0.4202 - val_accuracy: 0.8636\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8208 - val_loss: 0.4197 - val_accuracy: 0.8636\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8266 - val_loss: 0.4186 - val_accuracy: 0.8636\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8382 - val_loss: 0.4147 - val_accuracy: 0.8636\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8324 - val_loss: 0.4118 - val_accuracy: 0.8636\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8208 - val_loss: 0.4166 - val_accuracy: 0.8636\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8382 - val_loss: 0.4146 - val_accuracy: 0.8409\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8382 - val_loss: 0.4106 - val_accuracy: 0.8636\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8324 - val_loss: 0.4122 - val_accuracy: 0.8636\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8324 - val_loss: 0.4205 - val_accuracy: 0.8636\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8382 - val_loss: 0.4151 - val_accuracy: 0.8636\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8324 - val_loss: 0.4104 - val_accuracy: 0.8636\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8382 - val_loss: 0.4090 - val_accuracy: 0.8409\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8324 - val_loss: 0.4071 - val_accuracy: 0.8409\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8266 - val_loss: 0.4093 - val_accuracy: 0.8636\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3914 - accuracy: 0.8266 - val_loss: 0.4086 - val_accuracy: 0.8636\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8324 - val_loss: 0.4123 - val_accuracy: 0.8409\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3897 - accuracy: 0.8382 - val_loss: 0.4111 - val_accuracy: 0.8636\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.8382 - val_loss: 0.4112 - val_accuracy: 0.8636\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8439 - val_loss: 0.4088 - val_accuracy: 0.8636\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8439 - val_loss: 0.4096 - val_accuracy: 0.8409\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8439 - val_loss: 0.4092 - val_accuracy: 0.8636\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3868 - accuracy: 0.8324 - val_loss: 0.4064 - val_accuracy: 0.8636\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3861 - accuracy: 0.8324 - val_loss: 0.4047 - val_accuracy: 0.8409\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8324 - val_loss: 0.4108 - val_accuracy: 0.8409\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8382 - val_loss: 0.4069 - val_accuracy: 0.8409\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8324 - val_loss: 0.4047 - val_accuracy: 0.8636\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8324 - val_loss: 0.4023 - val_accuracy: 0.8636\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8324 - val_loss: 0.4058 - val_accuracy: 0.8409\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8324 - val_loss: 0.4022 - val_accuracy: 0.8409\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8324 - val_loss: 0.4008 - val_accuracy: 0.8636\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.8208 - val_loss: 0.4036 - val_accuracy: 0.8636\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 0.8439 - val_loss: 0.4046 - val_accuracy: 0.8409\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3804 - accuracy: 0.8382 - val_loss: 0.4031 - val_accuracy: 0.8409\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3801 - accuracy: 0.8324 - val_loss: 0.4011 - val_accuracy: 0.8636\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3805 - accuracy: 0.8324 - val_loss: 0.3997 - val_accuracy: 0.8409\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3817 - accuracy: 0.8324 - val_loss: 0.3987 - val_accuracy: 0.8409\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.8324 - val_loss: 0.4025 - val_accuracy: 0.8409\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8324 - val_loss: 0.3997 - val_accuracy: 0.8409\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8382 - val_loss: 0.4025 - val_accuracy: 0.8409\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8324 - val_loss: 0.4015 - val_accuracy: 0.8409\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8382 - val_loss: 0.4003 - val_accuracy: 0.8409\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.8382 - val_loss: 0.4018 - val_accuracy: 0.8636\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3813 - accuracy: 0.8324 - val_loss: 0.3984 - val_accuracy: 0.8409\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8324 - val_loss: 0.4016 - val_accuracy: 0.8409\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3774 - accuracy: 0.8382 - val_loss: 0.3999 - val_accuracy: 0.8636\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8382 - val_loss: 0.3972 - val_accuracy: 0.8409\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8266 - val_loss: 0.4012 - val_accuracy: 0.8409\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8382 - val_loss: 0.4023 - val_accuracy: 0.8409\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3760 - accuracy: 0.8382 - val_loss: 0.3981 - val_accuracy: 0.8409\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3759 - accuracy: 0.8324 - val_loss: 0.3948 - val_accuracy: 0.8409\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3789 - accuracy: 0.8439 - val_loss: 0.4009 - val_accuracy: 0.8409\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8324 - val_loss: 0.4002 - val_accuracy: 0.8409\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8266 - val_loss: 0.3959 - val_accuracy: 0.8636\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8382 - val_loss: 0.3998 - val_accuracy: 0.8409\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8382 - val_loss: 0.4014 - val_accuracy: 0.8409\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3757 - accuracy: 0.8382 - val_loss: 0.3980 - val_accuracy: 0.8409\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3746 - accuracy: 0.8324 - val_loss: 0.3974 - val_accuracy: 0.8409\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3730 - accuracy: 0.8382 - val_loss: 0.4028 - val_accuracy: 0.8409\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3780 - accuracy: 0.8382 - val_loss: 0.4026 - val_accuracy: 0.8409\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8324 - val_loss: 0.3925 - val_accuracy: 0.8409\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8266 - val_loss: 0.3973 - val_accuracy: 0.8409\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3738 - accuracy: 0.8324 - val_loss: 0.3979 - val_accuracy: 0.8409\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.8439 - val_loss: 0.4009 - val_accuracy: 0.8409\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.8324 - val_loss: 0.3947 - val_accuracy: 0.8409\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3723 - accuracy: 0.8324 - val_loss: 0.3958 - val_accuracy: 0.8409\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3720 - accuracy: 0.8324 - val_loss: 0.3974 - val_accuracy: 0.8409\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3731 - accuracy: 0.8324 - val_loss: 0.3954 - val_accuracy: 0.8409\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3712 - accuracy: 0.8324 - val_loss: 0.3981 - val_accuracy: 0.8409\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.8382 - val_loss: 0.3968 - val_accuracy: 0.8409\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.8439 - val_loss: 0.3984 - val_accuracy: 0.8409\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_normalized, Y_train, epochs=200, batch_size=20, validation_data=(X_test_normalized, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(301, 1)),  # Change the input shape\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model, normalize the data, and make predictions as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 250ms/step\n",
      "Predicted probability of a heart attack: [0.99974746]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "new_data = np.array([358,353,369,439,336,336,341,352,378,385,343,341,342,345,347,351,362,375,377,375,397,373,365,356,447,349,349,355,373,413,418,371,366,353,355,360,388,385,380,379,371,383,371,374,544,421,330,334,343,360,389,385,351,354,351,354,355,352,352,349,355,360,354,358,656,386,344,353,360,372,395,366,356,354,354,359,359,362,363,389,372,361,342,439,346,342,358,371,398,406,361,355,360,357,360,363,362,365,383,356,354,655,382,337,346,357,373,406,377,346,349,354,356,358,360,358,358,363,363,367,392,369,361,345,448,345,349,357,369,393,407,355,352,353,355,352,351,349,348,351,351,352,353,355,377,356,353,327,454,343,343,355,370,401,431,385,382,396,397,398,391,388,382,379,383,376,372,375,383,360,360,657,350,335,343,364,410,434,384,358,357,358,357,355,350,351,347,351,367,355,350,461,451,338,340,345,363,392,376,335,332,335,348,348,345,344,359,346,339,561,407,330,338,349,367,400,370,343,351,352,356,356,357,359,384,370,363,367,611,410,399,396,400,423,423,366,356,358,360,359,363,363,362,358,357,354,353,352,359,397,362,358,658,347,332,340,348,369,399,356,327,331,336,337,338,338,340,342,347,349,356,362,367,390,372,373,349,575,374,369,376,388,410,428,373,358,363,365,366,366,366,369,373,370,390,370,373,398,469,378,374]).reshape((1, 301, 1))\n",
    "prediction = model.predict(new_data)\n",
    "print(f\"Predicted probability of a heart attack: {prediction[0][0]}\")\n",
    "# 1 for normal, 0 for abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# prediction = model.predict([355])\n",
    "# print(f\"Predicted probability of a heart attack: {prediction[0][0]}\")\n",
    "# 1 for normal, 0 for abnormal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
