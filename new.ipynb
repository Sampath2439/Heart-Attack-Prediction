{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "22/22 [==============================] - 2s 19ms/step - loss: 0.6928 - accuracy: 0.4740 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.5780 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.5780 - val_loss: 0.6995 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.5780 - val_loss: 0.7049 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.5780 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5780 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.5780 - val_loss: 0.7005 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.5780 - val_loss: 0.6971 - val_accuracy: 0.5227\n",
      "Epoch 9/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.6069 - val_loss: 0.6964 - val_accuracy: 0.5455\n",
      "Epoch 10/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.6358 - val_loss: 0.6931 - val_accuracy: 0.5455\n",
      "Epoch 11/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6590 - val_loss: 0.6858 - val_accuracy: 0.5909\n",
      "Epoch 12/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6590 - val_loss: 0.6769 - val_accuracy: 0.6364\n",
      "Epoch 13/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6705 - val_loss: 0.6706 - val_accuracy: 0.6364\n",
      "Epoch 14/200\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6821 - val_loss: 0.6613 - val_accuracy: 0.6364\n",
      "Epoch 15/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6879 - val_loss: 0.6506 - val_accuracy: 0.6364\n",
      "Epoch 16/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6879 - val_loss: 0.6458 - val_accuracy: 0.6364\n",
      "Epoch 17/200\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.7168 - val_loss: 0.6303 - val_accuracy: 0.6364\n",
      "Epoch 18/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.7052 - val_loss: 0.6291 - val_accuracy: 0.6364\n",
      "Epoch 19/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7052 - val_loss: 0.6130 - val_accuracy: 0.6364\n",
      "Epoch 20/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7399 - val_loss: 0.6033 - val_accuracy: 0.6364\n",
      "Epoch 21/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7168 - val_loss: 0.5928 - val_accuracy: 0.7045\n",
      "Epoch 22/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7688 - val_loss: 0.5788 - val_accuracy: 0.6364\n",
      "Epoch 23/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7630 - val_loss: 0.5758 - val_accuracy: 0.6364\n",
      "Epoch 24/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7746 - val_loss: 0.5560 - val_accuracy: 0.7500\n",
      "Epoch 25/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7977 - val_loss: 0.5511 - val_accuracy: 0.6364\n",
      "Epoch 26/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.8035 - val_loss: 0.5399 - val_accuracy: 0.7955\n",
      "Epoch 27/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.8092 - val_loss: 0.5304 - val_accuracy: 0.7955\n",
      "Epoch 28/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.8150 - val_loss: 0.5293 - val_accuracy: 0.7045\n",
      "Epoch 29/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.8208 - val_loss: 0.5138 - val_accuracy: 0.7955\n",
      "Epoch 30/200\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7977 - val_loss: 0.5087 - val_accuracy: 0.8409\n",
      "Epoch 31/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8208 - val_loss: 0.5041 - val_accuracy: 0.7955\n",
      "Epoch 32/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.8208 - val_loss: 0.4937 - val_accuracy: 0.8182\n",
      "Epoch 33/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8150 - val_loss: 0.4897 - val_accuracy: 0.7955\n",
      "Epoch 34/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.8150 - val_loss: 0.4819 - val_accuracy: 0.8182\n",
      "Epoch 35/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.8150 - val_loss: 0.4768 - val_accuracy: 0.8409\n",
      "Epoch 36/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8092 - val_loss: 0.4752 - val_accuracy: 0.8182\n",
      "Epoch 37/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8150 - val_loss: 0.4720 - val_accuracy: 0.8182\n",
      "Epoch 38/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.8266 - val_loss: 0.4609 - val_accuracy: 0.8409\n",
      "Epoch 39/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8208 - val_loss: 0.4663 - val_accuracy: 0.8409\n",
      "Epoch 40/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.8150 - val_loss: 0.4578 - val_accuracy: 0.8409\n",
      "Epoch 41/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8266 - val_loss: 0.4500 - val_accuracy: 0.8636\n",
      "Epoch 42/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8092 - val_loss: 0.4528 - val_accuracy: 0.8409\n",
      "Epoch 43/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8266 - val_loss: 0.4527 - val_accuracy: 0.8409\n",
      "Epoch 44/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.8324 - val_loss: 0.4441 - val_accuracy: 0.8636\n",
      "Epoch 45/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8092 - val_loss: 0.4415 - val_accuracy: 0.8636\n",
      "Epoch 46/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8324 - val_loss: 0.4431 - val_accuracy: 0.8636\n",
      "Epoch 47/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8092 - val_loss: 0.4466 - val_accuracy: 0.8409\n",
      "Epoch 48/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8266 - val_loss: 0.4359 - val_accuracy: 0.8636\n",
      "Epoch 49/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8324 - val_loss: 0.4320 - val_accuracy: 0.8636\n",
      "Epoch 50/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8208 - val_loss: 0.4286 - val_accuracy: 0.8636\n",
      "Epoch 51/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8266 - val_loss: 0.4345 - val_accuracy: 0.8636\n",
      "Epoch 52/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8324 - val_loss: 0.4314 - val_accuracy: 0.8409\n",
      "Epoch 53/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8150 - val_loss: 0.4215 - val_accuracy: 0.8636\n",
      "Epoch 54/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8208 - val_loss: 0.4260 - val_accuracy: 0.8636\n",
      "Epoch 55/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8208 - val_loss: 0.4248 - val_accuracy: 0.8636\n",
      "Epoch 56/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8324 - val_loss: 0.4245 - val_accuracy: 0.8409\n",
      "Epoch 57/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8324 - val_loss: 0.4199 - val_accuracy: 0.8636\n",
      "Epoch 58/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8324 - val_loss: 0.4212 - val_accuracy: 0.8636\n",
      "Epoch 59/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8035 - val_loss: 0.4235 - val_accuracy: 0.8409\n",
      "Epoch 60/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8324 - val_loss: 0.4156 - val_accuracy: 0.8636\n",
      "Epoch 61/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8266 - val_loss: 0.4067 - val_accuracy: 0.8409\n",
      "Epoch 62/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8324 - val_loss: 0.4217 - val_accuracy: 0.8409\n",
      "Epoch 63/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8439 - val_loss: 0.4219 - val_accuracy: 0.8409\n",
      "Epoch 64/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8382 - val_loss: 0.4032 - val_accuracy: 0.8409\n",
      "Epoch 65/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8324 - val_loss: 0.4129 - val_accuracy: 0.8409\n",
      "Epoch 66/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8439 - val_loss: 0.4097 - val_accuracy: 0.8636\n",
      "Epoch 67/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8208 - val_loss: 0.4034 - val_accuracy: 0.8636\n",
      "Epoch 68/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8382 - val_loss: 0.4090 - val_accuracy: 0.8636\n",
      "Epoch 69/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8324 - val_loss: 0.4111 - val_accuracy: 0.8636\n",
      "Epoch 70/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8382 - val_loss: 0.4043 - val_accuracy: 0.8636\n",
      "Epoch 71/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8382 - val_loss: 0.4033 - val_accuracy: 0.8409\n",
      "Epoch 72/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8324 - val_loss: 0.4045 - val_accuracy: 0.8409\n",
      "Epoch 73/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8208 - val_loss: 0.4083 - val_accuracy: 0.8636\n",
      "Epoch 74/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8324 - val_loss: 0.4014 - val_accuracy: 0.8409\n",
      "Epoch 75/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8324 - val_loss: 0.4025 - val_accuracy: 0.8409\n",
      "Epoch 76/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8324 - val_loss: 0.4101 - val_accuracy: 0.8636\n",
      "Epoch 77/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8266 - val_loss: 0.4065 - val_accuracy: 0.8409\n",
      "Epoch 78/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8208 - val_loss: 0.3940 - val_accuracy: 0.8636\n",
      "Epoch 79/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8266 - val_loss: 0.4037 - val_accuracy: 0.8636\n",
      "Epoch 80/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8266 - val_loss: 0.4092 - val_accuracy: 0.8409\n",
      "Epoch 81/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8382 - val_loss: 0.3984 - val_accuracy: 0.8409\n",
      "Epoch 82/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8439 - val_loss: 0.3965 - val_accuracy: 0.8636\n",
      "Epoch 83/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8266 - val_loss: 0.4012 - val_accuracy: 0.8409\n",
      "Epoch 84/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8382 - val_loss: 0.4024 - val_accuracy: 0.8636\n",
      "Epoch 85/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8266 - val_loss: 0.4019 - val_accuracy: 0.8409\n",
      "Epoch 86/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8266 - val_loss: 0.4026 - val_accuracy: 0.8636\n",
      "Epoch 87/200\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8266 - val_loss: 0.3954 - val_accuracy: 0.8636\n",
      "Epoch 88/200\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8266 - val_loss: 0.3945 - val_accuracy: 0.8409\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.3940 - accuracy: 0.8636\n",
      "Test Loss: 0.3940460979938507\n",
      "Test Accuracy: 0.8636363744735718\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "\n",
    "# Your data\n",
    "heart_rates = np.array([353.0, 323.0, 323.0, 330.0, 332.0, 330.0, 330.0, 328.0, 338.0, 343.0, 366.0, 343.0, 331.0, 365.0, 404.0, 314.0, 315.0, 323.0, 328.0, 356.0, 348.0, 318.0, 321.0, 323.0, 322.0, 324.0, 323.0, 318.0, 326.0, 347.0, 328.0, 330.0, 363.0, 408.0, 322.0, 323.0, 333.0, 342.0, 364.0, 351.0, 325.0, 327.0, 329.0, 330.0, 329.0, 331.0, 339.0, 344.0, 326.0, 325.0, 628.0, 326.0, 314.0, 325.0, 332.0, 350.0, 362.0, 327.0, 323.0, 322.0, 327.0, 325.0, 323.0, 324.0, 347.0, 326.0, 323.0, 315.0, 534.0, 317.0, 308.0, 321.0, 330.0, 347.0, 357.0, 320.0, 314.0, 316.0, 323.0, 323.0, 322.0, 327.0, 333.0, 345.0, 331.0, 314.0, 307.0, 489.0, 317.0, 310.0, 318.0, 324.0, 348.0, 357.0, 319.0, 315.0, 317.0, 319.0, 316.0, 321.0, 319.0, 322.0, 327.0, 324.0, 352.0, 340.0, 328.0, 566.0, 342.0, 303.0, 314.0, 326.0, 360.0, 395.0, 359.0, 317.0, 315.0, 303.0, 324.0, 333.0, 465.0, 593.0, 645.0, 653.0, 656.0, 618.0, 587.0, 648.0, 655.0, 480.0, 458.0, 449.0, 447.0, 447.0, 400.0, 357.0, 345.0, 338.0, 325.0, 315.0, 307.0, 302.0, 296.0, 306.0, 296.0, 278.0, 278.0, 542.0, 275.0, 274.0, 281.0, 275.0, 315.0, 321.0, 280.0, 283.0, 259.0, 300.0, 257.0, 278.0, 281.0, 285.0, 295.0, 300.0, 271.0, 274.0, 618.0, 277.0, 271.0, 279.0, 332.0, 661.0, 661.0, 660.0, 660.0, 660.0, 661.0, 661.0, 660.0, 658.0, 585.0, 521.0, 449.0, 378.0, 591.0, 281.0, 215.0, 194.0, 187.0, 173.0, 182.0, 136.0, 121.0, 145.0, 128.0, 128.0, 130.0, 150.0, 151.0, 147.0, 149.0, 310.0, 169.0, 182.0, 188.0, 197.0, 220.0, 230.0, 220.0, 216.0, 243.0, 240.0, 257.0, 267.0, 289.0, 280.0, 283.0])\n",
    "labels = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(heart_rates, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train.reshape(-1, 1))\n",
    "X_test_normalized = scaler.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(1,)),  # Fix: Input shape should match the shape of your data\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_normalized, Y_train, epochs=200, batch_size=8, validation_data=(X_test_normalized, Y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_normalized, Y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
